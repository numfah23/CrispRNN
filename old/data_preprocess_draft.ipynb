{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read in full data\n",
    "data= pd.read_csv('../GenomeCRISPR_full05112017.csv')\n",
    "\n",
    "# read in sample data\n",
    "#data= pd.read_csv('../GenomeCRISPR_full05112017_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for top pubmed 29083409\n",
    "toppub_all_data = data[data['pubmed'] ==29083409]\n",
    "# filter for data from doench paper\n",
    "d = data[data['pubmed'] ==26780180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby celline and sequence, toppub\n",
    "toppub_grouped = toppub_all_data.groupby(['sequence','symbol']).median()['effect'].reset_index()\n",
    "# groupby celline and sequence, doench\n",
    "d_grouped = d.groupby(['sequence','symbol']).median()['effect'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby sequence to get unique seqs by gene, toppub\n",
    "groupby_seq = toppub_grouped.groupby(['sequence']).count().reset_index()\n",
    "groupby_gene = toppub_grouped.groupby(['symbol']).count().reset_index()\n",
    "# keeping only sequence column, toppub\n",
    "unique_seq_toppub = groupby_seq['sequence']\n",
    "groupby_gene = groupby_gene['symbol']\n",
    "\n",
    "# get unique seqs, doench\n",
    "d_groupby_seq = d_grouped.groupby(['sequence']).count().reset_index()\n",
    "unique_seq_d = d_groupby_seq['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join toppub data and doench data\n",
    "joined = d_grouped.merge(toppub_grouped, left_on=\"sequence\", right_on=\"sequence\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc diff between effects from 2 experiments\n",
    "joined[\"diff\"] = joined[\"effect_x\"] - joined[\"effect_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all doench to pickle\n",
    "pickle.dump(d_grouped[\"sequence\"], open(\"../d_all_data.p\", \"wb\"))\n",
    "pickle.dump(d_grouped[\"effect\"], open(\"../d_all_labels.p\", \"wb\"))\n",
    "\n",
    "\n",
    "# write only overalpped doench to pickle\n",
    "pickle.dump(joined[\"sequence\"], open(\"../d_intersect_data.p\", \"wb\"))\n",
    "pickle.dump(joined[\"effect_x\"], open(\"../d_intersect_labels.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for intersection seqs, plot effect scores from both pubs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(joined[\"effect_x\"], joined[\"effect_y\"], alpha=0.02)\n",
    "z = np.polyfit(joined[\"effect_x\"], joined[\"effect_y\"],1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(joined[\"effect_x\"], p(joined[\"effect_x\"]), \"r--\")\n",
    "\n",
    "plt.xlabel(\"Doench et al. effect size\")\n",
    "plt.ylabel(\"Meyers et al. (pubmed1) effect size\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6638872742071942, pvalue=0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc spearman corr\n",
    "import scipy.stats as st\n",
    "st.spearmanr(joined[\"effect_x\"], joined[\"effect_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot function\n",
    "\n",
    "e_dict = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1]}\n",
    "\n",
    "def one_hot(x):\n",
    "    return e_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encode the unique seqs, toppub\n",
    "one_hot_un_seq = unique_seq_toppub.apply(lambda x: map(one_hot, x))\n",
    "# doench\n",
    "one_hot_d = unique_seq_d.apply(lambda x: map(one_hot, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indices and append one_hot to df with seq, toppub\n",
    "unique_seq_toppub = unique_seq_toppub.reset_index()\n",
    "one_hot_un_seq = one_hot_un_seq.reset_index()\n",
    "groupby_gene = groupby_gene.reset_index()\n",
    "unique_seq_toppub['one_hot'] = one_hot_un_seq['sequence']\n",
    "# doench\n",
    "# reset indices and append one_hot to df with seq\n",
    "unique_seq_d = unique_seq_d.reset_index()\n",
    "one_hot_d = one_hot_d.reset_index()\n",
    "unique_seq_d['one_hot'] = one_hot_d['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge one hot encoding to data\n",
    "toppub_one_hot = toppub_grouped.merge(unique_seq_toppub,left_on=\"sequence\",right_on=\"sequence\", how=\"left\")\n",
    "d_one_hot = d_grouped.merge(unique_seq_d,left_on=\"sequence\",right_on=\"sequence\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge gene encoding to data # toppub only\n",
    "toppub_one_hot = toppub_one_hot.merge(groupby_gene,left_on=\"symbol\",right_on=\"symbol\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot features without gene, toppub\n",
    "features_no_gene = np.ndarray(shape=(toppub_one_hot.shape[0],23,4), dtype=int)\n",
    "for i in range(toppub_one_hot.shape[0]):\n",
    "    for j in range(len(toppub_one_hot['one_hot'][i])):\n",
    "        features_no_gene[i][j] = toppub_one_hot['one_hot'][i][j]\n",
    "        \n",
    "# one hot features without gene, toppub\n",
    "features_d = np.ndarray(shape=(d_one_hot.shape[0],23,4), dtype=int)\n",
    "for i in range(d_one_hot.shape[0]):\n",
    "    for j in range(len(d_one_hot['one_hot'][i])):\n",
    "        features_d[i][j] = d_one_hot['one_hot'][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "pickle.dump(features_no_gene, open(\"../features_no_gene.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot features with gene # toppub only\n",
    "# create empty numpy matrix for storing one hot features\n",
    "features = np.ndarray(shape=(toppub_one_hot.shape[0],23,5), dtype=int)\n",
    "# append gene to each one hot nucleotide\n",
    "for i in range(toppub_one_hot.shape[0]):\n",
    "    for j in range(len(toppub_one_hot['one_hot'][i])):\n",
    "        features[i][j] = toppub_one_hot['one_hot'][i][j] + [toppub_one_hot['index_y'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(features, open(\"../features.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regression\n",
    "def convert_labels(y):\n",
    "    return (y + 10)/float(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression labels\n",
    "labels = toppub_one_hot['effect']\n",
    "labels = np.array(list(map(lambda x: convert_labels(x), labels)))\n",
    "# doench\n",
    "labels_d = d_one_hot['effect']\n",
    "labels_d = np.array(list(map(lambda x: convert_labels(x), labels_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21-label classification labels\n",
    "num_classes=21\n",
    "labels_c = toppub_one_hot['effect']\n",
    "labels_c = np.array(list(map(lambda x: int(x+10), labels_c)))\n",
    "labels_c = np.eye(num_classes)[labels_c]\n",
    "# doench\n",
    "labels_d21 = d_one_hot['effect']\n",
    "labels_d21 = np.array(list(map(lambda x: int(x+10), labels_d21)))\n",
    "labels_d21 = np.eye(num_classes)[labels_d21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-label classification labels\n",
    "num_classes=3\n",
    "labels_3 = toppub_one_hot['effect']\n",
    "labels_3 = np.array(list(map(lambda x: int((x+10)/7), labels_3)))\n",
    "labels_3 = np.eye(num_classes)[labels_3]\n",
    "# doench\n",
    "labels_d3 = d_one_hot['effect']\n",
    "labels_d3 = np.array(list(map(lambda x: int((x+10)/7), labels_d3)))\n",
    "labels_d3 = np.eye(num_classes)[labels_d3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doench data, labels_d, labels_d21, labelsd_3\n",
    "pickle.dump(features_d, open(\"../d_data.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(labels_d, open(\"../d_labels_r.p\", \"wb\"))\n",
    "pickle.dump(labels_d21, open(\"../d_labels_21.p\", \"wb\"))\n",
    "pickle.dump(labels_d3, open(\"../d_labels_3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### for toppub only ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for with gene, regression\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features)) < 0.8\n",
    "\n",
    "train_data = features[msk]\n",
    "train_labels = labels[msk]\n",
    "\n",
    "test_val_data = features[~msk]\n",
    "test_val_labels = labels[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_GR.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_GR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_GR.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_GR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_GR.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_GR.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for no gene, regression\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features_no_gene)) < 0.8\n",
    "\n",
    "train_data = features_no_gene[msk]\n",
    "train_labels = labels[msk]\n",
    "\n",
    "test_val_data = features_no_gene[~msk]\n",
    "test_val_labels = labels[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with no gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_NR.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_NR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_NR.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_NR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_NR.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_NR.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for with gene, 21 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features)) < 0.8\n",
    "\n",
    "train_data = features[msk]\n",
    "train_labels = labels_c[msk]\n",
    "\n",
    "test_val_data = features[~msk]\n",
    "test_val_labels = labels_c[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_G21.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_G21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_G21.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_G21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_G21.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_G21.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for with gene, 3 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features)) < 0.8\n",
    "\n",
    "train_data = features[msk]\n",
    "train_labels = labels_3[msk]\n",
    "\n",
    "test_val_data = features[~msk]\n",
    "test_val_labels = labels_3[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_G3.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_G3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_G3.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_G3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_G3.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_G3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for no gene, 21 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features_no_gene)) < 0.8\n",
    "\n",
    "train_data = features_no_gene[msk]\n",
    "train_labels = labels_c[msk]\n",
    "\n",
    "test_val_data = features_no_gene[~msk]\n",
    "test_val_labels = labels_c[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with no gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_N21.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_N21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_N21.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_N21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_N21.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_N21.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for no gene, 3 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features_no_gene)) < 0.8\n",
    "\n",
    "train_data = features_no_gene[msk]\n",
    "train_labels = labels_3[msk]\n",
    "\n",
    "test_val_data = features_no_gene[~msk]\n",
    "test_val_labels = labels_3[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with no gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_N3.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_N3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_N3.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_N3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_N3.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_N3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for with gene\n",
    "pickle.dump(train_data, open(\"../train_data.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification without gene\n",
    "pickle.dump(train_data, open(\"../train_data2.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels2.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data2.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels2.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data2.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels2.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
