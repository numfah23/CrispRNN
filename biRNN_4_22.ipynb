{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression: 1 lable range 0-1\n",
    "train_data = pickle.load( open( \"../train_data.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../train_labels.p\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../test_data.p\", \"rb\" ) )\n",
    "test_labels = pickle.load( open( \"../test_labels.p\", \"rb\" ) )\n",
    "val_data = pickle.load( open( \"../val_data.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../val_labels.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification:  21 labels one hot, 4 features\n",
    "train_data = pickle.load( open( \"../train_data2.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../train_labels2.p\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../test_data2.p\", \"rb\" ) )\n",
    "test_labels = pickle.load( open( \"../test_labels2.p\", \"rb\" ) )\n",
    "val_data = pickle.load( open( \"../val_data2.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../val_labels2.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset of 10 samples\n",
    "subset_train_data = train_data[0:100]\n",
    "subset_train_labels = train_labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "# learning_rate = 0.001 # optimize this\n",
    "learning_rate = 0.01\n",
    "training_steps = 10000\n",
    "batch_size = 1 # 128\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 4\n",
    "    # 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 23\n",
    "    # 28 # timesteps\n",
    "num_hidden = 8 # ?\n",
    "    # 10 # hidden layer num of features\n",
    "num_classes = 21 # figure out how to do regression\n",
    "    # 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-22f61dfab070>:63: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this resets the graph - re-run tensor-flow specific things after it\n",
    "tf.reset_default_graph() \n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
    "    'out': tf.get_variable(\"my_int_variable\", [2*num_hidden, num_classes],\n",
    "  initializer=tf.glorot_uniform_initializer(seed = 23))\n",
    "#     tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=0.20)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=0.20)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                              dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output then sigmoid result to get output in range [0,1]\n",
    "\n",
    "    # no sigmoid\n",
    "#     print(len(outputs))\n",
    "#     print(outputs[-1])\n",
    "#     1/0\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "    \n",
    "    # sigmoid\n",
    "#     return tf.nn.sigmoid(tf.matmul(outputs[-1], weights['out']) + biases['out'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction = BiRNN(X, weights, biases)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y))\n",
    "# loss_op = tf.reduce_mean(tf.losses.mean_squared_error(labels=Y, predictions=prediction))\n",
    "\n",
    "# try reduce mean sq without using built in mse fn\n",
    "# loss_op = tf.reduce_mean(tf.square(Y - prediction))\n",
    "\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # switch to adam optimizer\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "prediction = tf.nn.softmax(prediction)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "# correct_pred = tf.equal(prediction, Y)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# accuracy = tf.reduce_mean(tf.losses.mean_squared_error(Y, prediction))\n",
    "# accuracy = tf.reduce_mean(abs(Y-prediction))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, x, y):\n",
    "    i = np.random.randint(0,x.shape[0], size=(batch_size))\n",
    "    return np.array(x[i]), np.array(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 4.0089, Validation Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 3.3258, Validation Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 3.1618, Validation Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 3.2193, Validation Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 2.1683, Validation Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 2.9130, Validation Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 3.2285, Validation Accuracy= 1.000\n",
      "Step 700, Minibatch Loss= 1.7716, Validation Accuracy= 1.000\n",
      "Step 800, Minibatch Loss= 2.5496, Validation Accuracy= 1.000\n",
      "Step 900, Minibatch Loss= 1.8190, Validation Accuracy= 1.000\n",
      "Step 1000, Minibatch Loss= 2.6758, Validation Accuracy= 1.000\n",
      "Step 1100, Minibatch Loss= 3.5094, Validation Accuracy= 1.000\n",
      "Step 1200, Minibatch Loss= 2.7748, Validation Accuracy= 1.000\n",
      "Step 1300, Minibatch Loss= 2.6002, Validation Accuracy= 1.000\n",
      "Step 1400, Minibatch Loss= 2.1792, Validation Accuracy= 1.000\n",
      "Step 1500, Minibatch Loss= 3.8445, Validation Accuracy= 1.000\n",
      "Step 1600, Minibatch Loss= 3.1608, Validation Accuracy= 1.000\n",
      "Step 1700, Minibatch Loss= 2.4058, Validation Accuracy= 1.000\n",
      "Step 1800, Minibatch Loss= 3.6797, Validation Accuracy= 1.000\n",
      "Step 1900, Minibatch Loss= 2.8047, Validation Accuracy= 1.000\n",
      "Step 2000, Minibatch Loss= 2.9756, Validation Accuracy= 1.000\n",
      "Step 2100, Minibatch Loss= 2.3394, Validation Accuracy= 1.000\n",
      "Step 2200, Minibatch Loss= 2.9877, Validation Accuracy= 1.000\n",
      "Step 2300, Minibatch Loss= 2.9766, Validation Accuracy= 1.000\n",
      "Step 2400, Minibatch Loss= 2.3823, Validation Accuracy= 1.000\n",
      "Step 2500, Minibatch Loss= 2.8057, Validation Accuracy= 1.000\n",
      "Step 2600, Minibatch Loss= 2.5439, Validation Accuracy= 1.000\n",
      "Step 2700, Minibatch Loss= 2.4761, Validation Accuracy= 1.000\n",
      "Step 2800, Minibatch Loss= 3.7692, Validation Accuracy= 1.000\n",
      "Step 2900, Minibatch Loss= 3.3430, Validation Accuracy= 1.000\n",
      "Step 3000, Minibatch Loss= 3.7671, Validation Accuracy= 1.000\n",
      "Step 3100, Minibatch Loss= 2.4293, Validation Accuracy= 1.000\n",
      "Step 3200, Minibatch Loss= 2.2203, Validation Accuracy= 1.000\n",
      "Step 3300, Minibatch Loss= 3.0577, Validation Accuracy= 1.000\n",
      "Step 3400, Minibatch Loss= 3.4904, Validation Accuracy= 1.000\n",
      "Step 3500, Minibatch Loss= 4.2679, Validation Accuracy= 1.000\n",
      "Step 3600, Minibatch Loss= 2.1174, Validation Accuracy= 1.000\n",
      "Step 3700, Minibatch Loss= 2.7777, Validation Accuracy= 1.000\n",
      "Step 3800, Minibatch Loss= 2.5823, Validation Accuracy= 1.000\n",
      "Step 3900, Minibatch Loss= 3.3070, Validation Accuracy= 1.000\n",
      "Step 4000, Minibatch Loss= 3.0603, Validation Accuracy= 1.000\n",
      "Step 4100, Minibatch Loss= 1.8693, Validation Accuracy= 1.000\n",
      "Step 4200, Minibatch Loss= 2.7763, Validation Accuracy= 1.000\n",
      "Step 4300, Minibatch Loss= 2.1219, Validation Accuracy= 1.000\n",
      "Step 4400, Minibatch Loss= 2.4749, Validation Accuracy= 1.000\n",
      "Step 4500, Minibatch Loss= 2.7271, Validation Accuracy= 1.000\n",
      "Step 4600, Minibatch Loss= 3.4487, Validation Accuracy= 1.000\n",
      "Step 4700, Minibatch Loss= 4.0757, Validation Accuracy= 1.000\n",
      "Step 4800, Minibatch Loss= 2.2033, Validation Accuracy= 1.000\n",
      "Step 4900, Minibatch Loss= 2.2739, Validation Accuracy= 1.000\n",
      "Step 5000, Minibatch Loss= 2.5598, Validation Accuracy= 1.000\n",
      "Step 5100, Minibatch Loss= 2.4917, Validation Accuracy= 1.000\n",
      "Step 5200, Minibatch Loss= 3.1814, Validation Accuracy= 1.000\n",
      "Step 5300, Minibatch Loss= 2.8790, Validation Accuracy= 1.000\n",
      "Step 5400, Minibatch Loss= 1.8681, Validation Accuracy= 1.000\n",
      "Step 5500, Minibatch Loss= 2.2093, Validation Accuracy= 1.000\n",
      "Step 5600, Minibatch Loss= 2.2872, Validation Accuracy= 1.000\n",
      "Step 5700, Minibatch Loss= 2.3234, Validation Accuracy= 1.000\n",
      "Step 5800, Minibatch Loss= 2.2219, Validation Accuracy= 1.000\n",
      "Step 5900, Minibatch Loss= 2.2350, Validation Accuracy= 1.000\n",
      "Step 6000, Minibatch Loss= 2.8142, Validation Accuracy= 1.000\n",
      "Step 6100, Minibatch Loss= 2.3878, Validation Accuracy= 1.000\n",
      "Step 6200, Minibatch Loss= 2.1344, Validation Accuracy= 1.000\n",
      "Step 6300, Minibatch Loss= 3.6782, Validation Accuracy= 1.000\n",
      "Step 6400, Minibatch Loss= 2.9084, Validation Accuracy= 1.000\n",
      "Step 6500, Minibatch Loss= 3.7177, Validation Accuracy= 1.000\n",
      "Step 6600, Minibatch Loss= 3.4607, Validation Accuracy= 1.000\n",
      "Step 6700, Minibatch Loss= 2.6211, Validation Accuracy= 1.000\n",
      "Step 6800, Minibatch Loss= 3.3431, Validation Accuracy= 1.000\n",
      "Step 6900, Minibatch Loss= 2.7078, Validation Accuracy= 1.000\n",
      "Step 7000, Minibatch Loss= 2.5496, Validation Accuracy= 1.000\n",
      "Step 7100, Minibatch Loss= 3.4311, Validation Accuracy= 1.000\n",
      "Step 7200, Minibatch Loss= 3.2109, Validation Accuracy= 1.000\n",
      "Step 7300, Minibatch Loss= 2.5761, Validation Accuracy= 1.000\n",
      "Step 7400, Minibatch Loss= 3.2348, Validation Accuracy= 1.000\n",
      "Step 7500, Minibatch Loss= 2.6915, Validation Accuracy= 1.000\n",
      "Step 7600, Minibatch Loss= 2.6684, Validation Accuracy= 1.000\n",
      "Step 7700, Minibatch Loss= 3.4763, Validation Accuracy= 1.000\n",
      "Step 7800, Minibatch Loss= 2.9859, Validation Accuracy= 1.000\n",
      "Step 7900, Minibatch Loss= 2.5065, Validation Accuracy= 1.000\n",
      "Step 8000, Minibatch Loss= 2.3861, Validation Accuracy= 1.000\n",
      "Step 8100, Minibatch Loss= 2.4468, Validation Accuracy= 1.000\n",
      "Step 8200, Minibatch Loss= 3.0793, Validation Accuracy= 1.000\n",
      "Step 8300, Minibatch Loss= 2.4338, Validation Accuracy= 1.000\n",
      "Step 8400, Minibatch Loss= 2.9489, Validation Accuracy= 1.000\n",
      "Step 8500, Minibatch Loss= 2.4734, Validation Accuracy= 1.000\n",
      "Step 8600, Minibatch Loss= 2.6158, Validation Accuracy= 1.000\n",
      "Step 8700, Minibatch Loss= 3.1330, Validation Accuracy= 1.000\n",
      "Step 8800, Minibatch Loss= 2.4811, Validation Accuracy= 1.000\n",
      "Step 8900, Minibatch Loss= 2.5727, Validation Accuracy= 1.000\n",
      "Step 9000, Minibatch Loss= 2.8178, Validation Accuracy= 1.000\n",
      "Step 9100, Minibatch Loss= 2.4670, Validation Accuracy= 1.000\n",
      "Step 9200, Minibatch Loss= 3.3307, Validation Accuracy= 1.000\n",
      "Step 9300, Minibatch Loss= 2.9270, Validation Accuracy= 1.000\n",
      "Step 9400, Minibatch Loss= 3.2818, Validation Accuracy= 1.000\n",
      "Step 9500, Minibatch Loss= 3.0363, Validation Accuracy= 1.000\n",
      "Step 9600, Minibatch Loss= 2.7170, Validation Accuracy= 1.000\n",
      "Step 9700, Minibatch Loss= 2.5563, Validation Accuracy= 1.000\n",
      "Step 9800, Minibatch Loss= 2.5022, Validation Accuracy= 1.000\n",
      "Step 9900, Minibatch Loss= 4.1418, Validation Accuracy= 1.000\n",
      "Step 10000, Minibatch Loss= 3.0681, Validation Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Loss = 0.1486\n"
     ]
    }
   ],
   "source": [
    "# train_data = subset_train_data\n",
    "# train_labels = subset_train_labels\n",
    "# val_data = subset_train_data\n",
    "# val_labels = subset_train_labels\n",
    "\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = get_batch(batch_size, train_data, train_labels)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "#         batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "#         batch_y = batch_y.reshape((batch_size, num_classes))\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run([train_op, loss_op, prediction], feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "#             loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})            \n",
    "\n",
    "            loss = sess.run(loss_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            #val accuracy\n",
    "            acc = 1\n",
    "\n",
    "\n",
    "\n",
    "#             val_pr\n",
    "#             for i in range(val_labels.shape[0]):\n",
    "#                 val_labels = val_labels.reshape((val_labels.shape[0], num_classes))\n",
    "#                 x = val_data[i].reshape((batch_size,timesteps, num_input))\n",
    "#                 y = val_labels[i].reshape((batch_size,num_classes))\n",
    "#                 val_preds.append(sess.run(accuracy, feed_dict={X: x}))      \n",
    "\n",
    "#             acc = np.mean(val_preds)\n",
    "\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Validation Accuracy= \" + \\\n",
    "                     \"{:.3f}\".format(acc))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#             preds = sess.run(accuracy, feed_dict={X: batch_x})            \n",
    "#             print preds\n",
    "            \n",
    "#             print batch_y\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist val images\n",
    "    accs = []\n",
    "    val_preds = []\n",
    "    for i in range(val_labels.shape[0]/batch_size):\n",
    "        val_labels = val_labels.reshape((val_labels.shape[0], num_classes))\n",
    "        x = val_data[i*batch_size: i*batch_size + batch_size].reshape((batch_size,timesteps, num_input))\n",
    "        y = val_labels[i*batch_size:i*batch_size + batch_size].reshape((batch_size,num_classes))\n",
    "        val_preds.append(sess.run(prediction, feed_dict={X: x}))      \n",
    "        accs.append(sess.run(accuracy, feed_dict={X: x, Y:y}))\n",
    "    \n",
    "    l = np.mean(accs)\n",
    "    print(\"Loss = \" + \"{:.4f}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.argmax(val_preds, axis=2), np.argmax(val_labels, axis=1), alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
