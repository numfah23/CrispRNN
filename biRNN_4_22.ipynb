{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression: 1 lable range 0-1\n",
    "train_data = pickle.load( open( \"../train_data.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../train_labels.p\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../test_data.p\", \"rb\" ) )\n",
    "test_labels = pickle.load( open( \"../test_labels.p\", \"rb\" ) )\n",
    "val_data = pickle.load( open( \"../val_data.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../val_labels.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification:  21 labels one hot, 4 features\n",
    "train_data = pickle.load( open( \"../train_data2.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../train_labels2.p\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../test_data2.p\", \"rb\" ) )\n",
    "test_labels = pickle.load( open( \"../test_labels2.p\", \"rb\" ) )\n",
    "val_data = pickle.load( open( \"../val_data2.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../val_labels2.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset of 10 samples\n",
    "subset_train_data = train_data[0:10000]\n",
    "subset_train_labels = train_labels[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "# learning_rate = 0.001 # optimize this\n",
    "learning_rate = 0.1\n",
    "training_steps = 100000\n",
    "batch_size = 1 # 128\n",
    "display_step = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 4\n",
    "    # 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 23\n",
    "    # 28 # timesteps\n",
    "num_hidden = 32 # ?\n",
    "    # 10 # hidden layer num of features\n",
    "num_classes = 21 # figure out how to do regression\n",
    "    # 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this resets the graph - re-run tensor-flow specific things after it\n",
    "tf.reset_default_graph() \n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
    "    'out': tf.get_variable(\"my_int_variable\", [2*num_hidden, num_classes],\n",
    "  initializer=tf.glorot_uniform_initializer(seed = 23))\n",
    "#     tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=0.20)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=0.20)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                              dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output then sigmoid result to get output in range [0,1]\n",
    "\n",
    "    # no sigmoid\n",
    "#     print(len(outputs))\n",
    "#     print(outputs[-1])\n",
    "#     1/0\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "    \n",
    "    # sigmoid\n",
    "#     return tf.nn.sigmoid(tf.matmul(outputs[-1], weights['out']) + biases['out'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction = BiRNN(X, weights, biases)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y))\n",
    "# loss_op = tf.reduce_mean(tf.losses.mean_squared_error(labels=Y, predictions=prediction))\n",
    "\n",
    "# try reduce mean sq without using built in mse fn\n",
    "# loss_op = tf.reduce_mean(tf.square(Y - prediction))\n",
    "\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # switch to adam optimizer\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "# prediction = tf.nn.softmax(prediction)\n",
    "prediction = tf.argmax(tf.nn.softmax(prediction), 1)\n",
    "\n",
    "\n",
    "# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "correct_pred = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# accuracy = tf.reduce_mean(tf.losses.mean_squared_error(Y, prediction))\n",
    "# accuracy = tf.reduce_mean(abs(Y-prediction))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, x, y):\n",
    "    i = np.random.randint(0,x.shape[0], size=(batch_size))\n",
    "    return np.array(x[i]), np.array(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.4436, Validation Accuracy= 0.080\n",
      "Step 5000, Minibatch Loss= 3.6240, Validation Accuracy= 0.091\n",
      "Step 10000, Minibatch Loss= 3.0743, Validation Accuracy= 0.158\n",
      "Step 15000, Minibatch Loss= 2.1626, Validation Accuracy= 0.074\n",
      "Step 20000, Minibatch Loss= 4.0818, Validation Accuracy= 0.158\n",
      "Step 25000, Minibatch Loss= 2.0442, Validation Accuracy= 0.091\n",
      "Step 30000, Minibatch Loss= 3.1688, Validation Accuracy= 0.158\n",
      "Step 35000, Minibatch Loss= 2.5251, Validation Accuracy= 0.091\n",
      "Step 40000, Minibatch Loss= 3.1072, Validation Accuracy= 0.158\n",
      "Step 45000, Minibatch Loss= 3.0396, Validation Accuracy= 0.158\n",
      "Step 50000, Minibatch Loss= 2.2267, Validation Accuracy= 0.158\n",
      "Step 55000, Minibatch Loss= 2.4838, Validation Accuracy= 0.158\n",
      "Step 60000, Minibatch Loss= 3.9616, Validation Accuracy= 0.088\n",
      "Step 65000, Minibatch Loss= 3.5226, Validation Accuracy= 0.158\n",
      "Step 70000, Minibatch Loss= 3.2470, Validation Accuracy= 0.158\n",
      "Step 75000, Minibatch Loss= 3.0748, Validation Accuracy= 0.158\n",
      "Step 80000, Minibatch Loss= 2.1969, Validation Accuracy= 0.158\n",
      "Step 85000, Minibatch Loss= 2.6561, Validation Accuracy= 0.091\n",
      "Step 90000, Minibatch Loss= 3.0982, Validation Accuracy= 0.158\n",
      "Step 95000, Minibatch Loss= 3.3073, Validation Accuracy= 0.158\n",
      "Step 100000, Minibatch Loss= 1.4510, Validation Accuracy= 0.158\n",
      "Optimization Finished!\n",
      "Loss = 0.1577\n"
     ]
    }
   ],
   "source": [
    "train_data = subset_train_data\n",
    "train_labels = subset_train_labels\n",
    "val_data = subset_train_data\n",
    "val_labels = subset_train_labels\n",
    "\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = get_batch(batch_size, train_data, train_labels)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "#         batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "#         batch_y = batch_y.reshape((batch_size, num_classes))\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run([train_op, loss_op, prediction], feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "#             loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})            \n",
    "\n",
    "            loss = sess.run(loss_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            #val accuracy\n",
    "            acc = 1\n",
    "\n",
    "\n",
    "\n",
    "#             val_preds = []\n",
    "            accs = []\n",
    "            for i in range(val_labels.shape[0]/batch_size):\n",
    "                val_labels = val_labels.reshape((val_labels.shape[0], num_classes))\n",
    "                x = val_data[i*batch_size: i*batch_size + batch_size].reshape((batch_size,timesteps, num_input))\n",
    "                y = val_labels[i*batch_size:i*batch_size + batch_size].reshape((batch_size,num_classes))\n",
    "#                 val_preds.append(sess.run(prediction, feed_dict={X: x}))      \n",
    "                accs.append(sess.run(accuracy, feed_dict={X: x, Y:y}))\n",
    "            acc = np.mean(accs)\n",
    "\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Validation Accuracy= \" + \\\n",
    "                     \"{:.3f}\".format(acc))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#             preds = sess.run(accuracy, feed_dict={X: batch_x})            \n",
    "#             print preds\n",
    "            \n",
    "#             print batch_y\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist val images\n",
    "    accs = []\n",
    "    val_preds = []\n",
    "    for i in range(val_labels.shape[0]/batch_size):\n",
    "        val_labels = val_labels.reshape((val_labels.shape[0], num_classes))\n",
    "        x = val_data[i*batch_size: i*batch_size + batch_size].reshape((batch_size,timesteps, num_input))\n",
    "        y = val_labels[i*batch_size:i*batch_size + batch_size].reshape((batch_size,num_classes))\n",
    "        val_preds.append(sess.run(prediction, feed_dict={X: x}))      \n",
    "        accs.append(sess.run(accuracy, feed_dict={X: x, Y:y}))\n",
    "    \n",
    "    l = np.mean(accs)\n",
    "    print(\"Loss = \" + \"{:.4f}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = [v[0] for v in val_preds]\n",
    "plt.scatter(preds, np.argmax(val_labels, axis=1), alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
