{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# input and setting: edit these\n",
    "#################################\n",
    "\n",
    "# file should have columns called \"sequence\" with 23 nts and \"effect\"\n",
    "# train, val, test on samplepubmed1\n",
    "filename = 'data/samplePubMed1.csv'\n",
    "outfile_prefix = 'samplePubMed1'\n",
    "\n",
    "# percent of data to be split into train, val, test \n",
    "# train, val, test on samplepubmed1\n",
    "n_train, n_val, n_test = 0.8, 0.1, 0.1\n",
    "\n",
    "# type of model: either 'regression' or 'classification'\n",
    "# model_type = 'regression'\n",
    "model_type = 'classification'\n",
    "\n",
    "# # generate test set only on samplepubmed2\n",
    "filename = 'data/samplePubMed2.csv'\n",
    "outfile_prefix = 'samplePubMed2'\n",
    "n_train, n_val, n_test = 0, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby sequence (for model, same seq can not have multiple effects)\n",
    "data = data.groupby(['sequence']).median()['effect'].reset_index()\n",
    "\n",
    "# shuffle data so that we can split into training val test\n",
    "data = shuffle(data, random_state=23)\n",
    "\n",
    "# get unique seqs\n",
    "unique_seqs = data['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot function\n",
    "def one_hot(x):\n",
    "    e_dict = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1]}\n",
    "    return e_dict[x]\n",
    "\n",
    "# one hot encode unique seqs\n",
    "one_hot_un_seq = unique_seqs.apply(lambda x: map(one_hot, x))\n",
    "one_hot_un_seq = one_hot_un_seq.reset_index()\n",
    "\n",
    "features = np.ndarray(shape=(one_hot_un_seq['sequence'].shape[0],23,4), dtype=int)\n",
    "for i in range(one_hot_un_seq.shape[0]):\n",
    "    for j in range(23):\n",
    "        features[i][j] = one_hot_un_seq['sequence'][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"regression\":\n",
    "    def convert_labels_reg(y):\n",
    "        return (y + 10)/float(20)\n",
    "    labels = data['effect']\n",
    "    labels = np.array(list(map(lambda x: convert_labels_reg(x), labels)))\n",
    "else: # 21-label classification labels\n",
    "    num_classes=21\n",
    "    labels = data['effect']\n",
    "    labels = np.array(list(map(lambda x: int(x+10), labels)))\n",
    "    labels = np.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split shuffled data into training, validation, testing\n",
    "train_stop = int(n_train*len(one_hot_un_seq))\n",
    "val_stop = train_stop + int(n_val*len(one_hot_un_seq))\n",
    "\n",
    "train_data = features[0:train_stop]\n",
    "train_labels = labels[0:train_stop]\n",
    "\n",
    "val_data = features[train_stop:val_stop]\n",
    "val_labels = labels[train_stop:val_stop]\n",
    "\n",
    "test_data = features[val_stop: len(one_hot_un_seq)]\n",
    "test_labels = labels[val_stop: len(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output files as pickle\n",
    "if n_train != 0:\n",
    "    pickle.dump(train_data, open(\"data/\" + outfile_prefix + \"_train_data.p\", \"wb\"))\n",
    "    pickle.dump(train_labels, open(\"data/\" + outfile_prefix + \"_train_labels.p\", \"wb\"))\n",
    "\n",
    "if n_test != 0:\n",
    "    pickle.dump(test_data, open(\"data/\" + outfile_prefix + \"_test_data.p\", \"wb\"))\n",
    "    pickle.dump(test_labels, open(\"data/\" + outfile_prefix + \"_test_labels.p\", \"wb\"))\n",
    "\n",
    "if n_val != 0:\n",
    "    pickle.dump(val_data, open(\"data/\" + outfile_prefix + \"_val_data.p\", \"wb\"))\n",
    "    pickle.dump(val_labels, open(\"data/\" + outfile_prefix + \"_val_labels.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
