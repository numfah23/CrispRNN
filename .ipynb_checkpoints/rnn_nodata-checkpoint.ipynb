{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pickle.load( open( \"../train_data.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../train_labels.p\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../test_data.p\", \"rb\" ) )\n",
    "test_labels = pickle.load( open( \"../test_labels.p\", \"rb\" ) )\n",
    "val_data = pickle.load( open( \"../test_data.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../test_labels.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "# learning_rate = 0.001 # optimize this\n",
    "learning_rate = 0.1\n",
    "training_steps = 10000\n",
    "batch_size = 5 # 128\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 5\n",
    "    # 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 23\n",
    "    # 28 # timesteps\n",
    "num_hidden = 50 # ?\n",
    "    # 128 # hidden layer num of features\n",
    "num_classes = 1 # figure out how to do regression\n",
    "    # 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this resets the graph - re-run tensor-flow specific things after it\n",
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
    "    'out': tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                              dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                        dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output then sigmoid result to get output in range [0,1]\n",
    "#     return tf.nn.sigmoid(tf.matmul(outputs[-1], weights['out']) + biases['out'])\n",
    "\n",
    "    # no sigmoid\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = BiRNN(X, weights, biases)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "# loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "loss_op = tf.reduce_mean(tf.losses.mean_squared_error(labels=Y, predictions=prediction))\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # switch to adam optimizer\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "# correct_pred = tf.equal(prediction, Y)\n",
    "\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# accuracy = tf.reduce_mean(tf.losses.mean_squared_error(Y, prediction))\n",
    "accuracy = tf.reduce_mean(abs(Y-prediction))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(batch_size, x, y):\n",
    "    i = np.random.randint(0,x.shape[0], size=(batch_size))\n",
    "    return np.array(x[i]), np.array(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45, 0.35, 0.5 , ..., 0.45, 0.1 , 0.75])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.0918, Training Accuracy= 0.252\n",
      "[[0.23829365]\n",
      " [0.23829365]\n",
      " [0.23829365]\n",
      " [0.23829365]\n",
      " [0.23829365]]\n",
      "Step 200, Minibatch Loss= 0.0510, Training Accuracy= 0.211\n",
      "[[0.63472414]\n",
      " [0.63472414]\n",
      " [0.63472414]\n",
      " [0.63472414]\n",
      " [0.63472414]]\n",
      "Step 400, Minibatch Loss= 0.0368, Training Accuracy= 0.171\n",
      "[[0.34899342]\n",
      " [0.34899342]\n",
      " [0.34899342]\n",
      " [0.34899342]\n",
      " [0.34899342]]\n",
      "Step 600, Minibatch Loss= 0.0264, Training Accuracy= 0.115\n",
      "[[0.591957]\n",
      " [0.591957]\n",
      " [0.591957]\n",
      " [0.591957]\n",
      " [0.591957]]\n",
      "Step 800, Minibatch Loss= 0.0759, Training Accuracy= 0.241\n",
      "[[0.5320916]\n",
      " [0.5320916]\n",
      " [0.5320916]\n",
      " [0.5320916]\n",
      " [0.5320916]]\n",
      "Step 1000, Minibatch Loss= 0.0244, Training Accuracy= 0.142\n",
      "[[0.6372646]\n",
      " [0.6372646]\n",
      " [0.6372646]\n",
      " [0.6372646]\n",
      " [0.6372646]]\n",
      "Step 1200, Minibatch Loss= 0.0583, Training Accuracy= 0.168\n",
      "[[0.66320634]\n",
      " [0.66320634]\n",
      " [0.66320634]\n",
      " [0.66320634]\n",
      " [0.66320634]]\n",
      "Step 1400, Minibatch Loss= 0.1147, Training Accuracy= 0.292\n",
      "[[0.83198]\n",
      " [0.83198]\n",
      " [0.83198]\n",
      " [0.83198]\n",
      " [0.83198]]\n",
      "Step 1600, Minibatch Loss= 0.0919, Training Accuracy= 0.256\n",
      "[[0.8593482]\n",
      " [0.8593482]\n",
      " [0.8593482]\n",
      " [0.8593482]\n",
      " [0.8593482]]\n",
      "Step 1800, Minibatch Loss= 0.0542, Training Accuracy= 0.150\n",
      "[[0.5987897]\n",
      " [0.5987897]\n",
      " [0.5987897]\n",
      " [0.5987897]\n",
      " [0.5987897]]\n",
      "Step 2000, Minibatch Loss= 0.0958, Training Accuracy= 0.290\n",
      "[[0.34844565]\n",
      " [0.34844565]\n",
      " [0.34844565]\n",
      " [0.34844565]\n",
      " [0.34844565]]\n",
      "Step 2200, Minibatch Loss= 0.0896, Training Accuracy= 0.263\n",
      "[[0.4162978]\n",
      " [0.4162978]\n",
      " [0.4162978]\n",
      " [0.4162978]\n",
      " [0.4162978]]\n",
      "Step 2400, Minibatch Loss= 0.0080, Training Accuracy= 0.063\n",
      "[[0.68524843]\n",
      " [0.68524843]\n",
      " [0.68524843]\n",
      " [0.68524843]\n",
      " [0.68524843]]\n",
      "Step 2600, Minibatch Loss= 0.1247, Training Accuracy= 0.310\n",
      "[[0.2497412]\n",
      " [0.2497412]\n",
      " [0.2497412]\n",
      " [0.2497412]\n",
      " [0.2497412]]\n",
      "Step 2800, Minibatch Loss= 0.0169, Training Accuracy= 0.100\n",
      "[[0.7482176]\n",
      " [0.7482176]\n",
      " [0.7482176]\n",
      " [0.7482176]\n",
      " [0.7482176]]\n",
      "Step 3000, Minibatch Loss= 0.4148, Training Accuracy= 0.633\n",
      "[[-0.05263448]\n",
      " [-0.05263448]\n",
      " [-0.05263448]\n",
      " [-0.05263448]\n",
      " [-0.05263448]]\n",
      "Step 3200, Minibatch Loss= 0.0553, Training Accuracy= 0.161\n",
      "[[0.50244987]\n",
      " [0.50244987]\n",
      " [0.50244987]\n",
      " [0.50244987]\n",
      " [0.50244987]]\n",
      "Step 3400, Minibatch Loss= 0.1483, Training Accuracy= 0.364\n",
      "[[0.309757]\n",
      " [0.309757]\n",
      " [0.309757]\n",
      " [0.309757]\n",
      " [0.309757]]\n",
      "Step 3600, Minibatch Loss= 0.0915, Training Accuracy= 0.238\n",
      "[[0.74664676]\n",
      " [0.74664676]\n",
      " [0.74664676]\n",
      " [0.74664676]\n",
      " [0.74664676]]\n",
      "Step 3800, Minibatch Loss= 0.0434, Training Accuracy= 0.189\n",
      "[[0.4537449]\n",
      " [0.4537449]\n",
      " [0.4537449]\n",
      " [0.4537449]\n",
      " [0.4537449]]\n",
      "Step 4000, Minibatch Loss= 0.0433, Training Accuracy= 0.145\n",
      "[[0.5233824]\n",
      " [0.5233824]\n",
      " [0.5233824]\n",
      " [0.5233824]\n",
      " [0.5233824]]\n",
      "Step 4200, Minibatch Loss= 0.0290, Training Accuracy= 0.132\n",
      "[[0.43838465]\n",
      " [0.43838465]\n",
      " [0.43838465]\n",
      " [0.43838465]\n",
      " [0.43838465]]\n",
      "Step 4400, Minibatch Loss= 0.0278, Training Accuracy= 0.124\n",
      "[[0.46970254]\n",
      " [0.46970254]\n",
      " [0.46970254]\n",
      " [0.46970254]\n",
      " [0.46970254]]\n",
      "Step 4600, Minibatch Loss= 0.1453, Training Accuracy= 0.305\n",
      "[[0.7245196]\n",
      " [0.7245196]\n",
      " [0.7245196]\n",
      " [0.7245196]\n",
      " [0.7245196]]\n",
      "Step 4800, Minibatch Loss= 0.0048, Training Accuracy= 0.044\n",
      "[[0.5927466]\n",
      " [0.5927466]\n",
      " [0.5927466]\n",
      " [0.5927466]\n",
      " [0.5927466]]\n",
      "Step 5000, Minibatch Loss= 0.0229, Training Accuracy= 0.127\n",
      "[[0.56294554]\n",
      " [0.56294554]\n",
      " [0.56294554]\n",
      " [0.56294554]\n",
      " [0.56294554]]\n",
      "Step 5200, Minibatch Loss= 0.0490, Training Accuracy= 0.204\n",
      "[[0.4280107]\n",
      " [0.4280107]\n",
      " [0.4280107]\n",
      " [0.4280107]\n",
      " [0.4280107]]\n",
      "Step 5400, Minibatch Loss= 0.0433, Training Accuracy= 0.184\n",
      "[[0.4684453]\n",
      " [0.4684453]\n",
      " [0.4684453]\n",
      " [0.4684453]\n",
      " [0.4684453]]\n",
      "Step 5600, Minibatch Loss= 0.0264, Training Accuracy= 0.134\n",
      "[[0.471197]\n",
      " [0.471197]\n",
      " [0.471197]\n",
      " [0.471197]\n",
      " [0.471197]]\n",
      "Step 5800, Minibatch Loss= 0.5978, Training Accuracy= 0.755\n",
      "[[-0.24527681]\n",
      " [-0.24527681]\n",
      " [-0.24527681]\n",
      " [-0.24527681]\n",
      " [-0.24527681]]\n",
      "Step 6000, Minibatch Loss= 0.1412, Training Accuracy= 0.361\n",
      "[[0.18912649]\n",
      " [0.18912649]\n",
      " [0.18912649]\n",
      " [0.18912649]\n",
      " [0.18912649]]\n",
      "Step 6200, Minibatch Loss= 0.0829, Training Accuracy= 0.258\n",
      "[[0.37037027]\n",
      " [0.37037027]\n",
      " [0.37037027]\n",
      " [0.37037027]\n",
      " [0.37037027]]\n",
      "Step 6400, Minibatch Loss= 0.0397, Training Accuracy= 0.172\n",
      "[[0.44602048]\n",
      " [0.44602048]\n",
      " [0.44602048]\n",
      " [0.44602048]\n",
      " [0.44602048]]\n",
      "Step 6600, Minibatch Loss= 0.0874, Training Accuracy= 0.235\n",
      "[[0.05759394]\n",
      " [0.05759394]\n",
      " [0.05759394]\n",
      " [0.05759394]\n",
      " [0.05759394]]\n",
      "Step 6800, Minibatch Loss= 0.1608, Training Accuracy= 0.350\n",
      "[[0.25149786]\n",
      " [0.25149786]\n",
      " [0.25149786]\n",
      " [0.25149786]\n",
      " [0.25149786]]\n",
      "Step 7000, Minibatch Loss= 0.1835, Training Accuracy= 0.342\n",
      "[[0.8039294]\n",
      " [0.8039294]\n",
      " [0.8039294]\n",
      " [0.8039294]\n",
      " [0.8039294]]\n",
      "Step 7200, Minibatch Loss= 0.0889, Training Accuracy= 0.250\n",
      "[[0.31606603]\n",
      " [0.31606603]\n",
      " [0.31606603]\n",
      " [0.31606603]\n",
      " [0.31606603]]\n",
      "Step 7400, Minibatch Loss= 0.0167, Training Accuracy= 0.115\n",
      "[[0.6252177]\n",
      " [0.6252177]\n",
      " [0.6252177]\n",
      " [0.6252177]\n",
      " [0.6252177]]\n",
      "Step 7600, Minibatch Loss= 0.1063, Training Accuracy= 0.310\n",
      "[[0.1659987]\n",
      " [0.1659987]\n",
      " [0.1659987]\n",
      " [0.1659987]\n",
      " [0.1659987]]\n",
      "Step 7800, Minibatch Loss= 0.0274, Training Accuracy= 0.147\n",
      "[[0.38849533]\n",
      " [0.38849533]\n",
      " [0.38849533]\n",
      " [0.38849533]\n",
      " [0.38849533]]\n",
      "Step 8000, Minibatch Loss= 0.0607, Training Accuracy= 0.164\n",
      "[[0.7060047]\n",
      " [0.7060047]\n",
      " [0.7060047]\n",
      " [0.7060047]\n",
      " [0.7060047]]\n",
      "Step 8200, Minibatch Loss= 0.0404, Training Accuracy= 0.177\n",
      "[[0.57146585]\n",
      " [0.57146585]\n",
      " [0.57146585]\n",
      " [0.57146585]\n",
      " [0.57146585]]\n",
      "Step 8400, Minibatch Loss= 0.1778, Training Accuracy= 0.376\n",
      "[[0.8957565]\n",
      " [0.8957565]\n",
      " [0.8957565]\n",
      " [0.8957565]\n",
      " [0.8957565]]\n",
      "Step 8600, Minibatch Loss= 3.8793, Training Accuracy= 1.961\n",
      "[[2.631306]\n",
      " [2.631306]\n",
      " [2.631306]\n",
      " [2.631306]\n",
      " [2.631306]]\n",
      "Step 8800, Minibatch Loss= 0.1126, Training Accuracy= 0.313\n",
      "[[0.16695893]\n",
      " [0.16695893]\n",
      " [0.16695893]\n",
      " [0.16695893]\n",
      " [0.16695893]]\n",
      "Step 9000, Minibatch Loss= 0.0488, Training Accuracy= 0.173\n",
      "[[0.55489504]\n",
      " [0.55489504]\n",
      " [0.55489504]\n",
      " [0.55489504]\n",
      " [0.55489504]]\n",
      "Step 9200, Minibatch Loss= 0.0320, Training Accuracy= 0.137\n",
      "[[0.6161419]\n",
      " [0.6161419]\n",
      " [0.6161419]\n",
      " [0.6161419]\n",
      " [0.6161419]]\n",
      "Step 9400, Minibatch Loss= 0.0161, Training Accuracy= 0.116\n",
      "[[0.47087014]\n",
      " [0.47087014]\n",
      " [0.47087014]\n",
      " [0.47087014]\n",
      " [0.47087014]]\n",
      "Step 9600, Minibatch Loss= 0.0345, Training Accuracy= 0.143\n",
      "[[0.564464]\n",
      " [0.564464]\n",
      " [0.564464]\n",
      " [0.564464]\n",
      " [0.564464]]\n",
      "Step 9800, Minibatch Loss= 0.0701, Training Accuracy= 0.236\n",
      "[[0.30731893]\n",
      " [0.30731893]\n",
      " [0.30731893]\n",
      " [0.30731893]\n",
      " [0.30731893]]\n",
      "Step 10000, Minibatch Loss= 0.2545, Training Accuracy= 0.475\n",
      "[[0.92489976]\n",
      " [0.92489976]\n",
      " [0.92489976]\n",
      " [0.92489976]\n",
      " [0.92489976]]\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "x, y = train_data, train_labels\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = get_train_data(batch_size, x,y)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "#         batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        \n",
    "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        batch_y = batch_y.reshape((batch_size, num_classes))\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "#             loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        \n",
    "            preds = sess.run(prediction, feed_dict={X: batch_x})\n",
    "            print preds\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "#     test_len = 128\n",
    "#     test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "#     test_label = mnist.test.labels[:test_len]\n",
    "#     print(\"Testing Accuracy:\", \\\n",
    "#         sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print prediction.eval(feed_dict={X: batch_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3 ],\n",
       "       [0.55],\n",
       "       [0.65],\n",
       "       [0.55],\n",
       "       [0.2 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8-0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_data, train_labels\n",
    "batch_x, batch_y = get_train_data(batch_size, x,y)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "#         batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        \n",
    "batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "batch_y = batch_y.reshape((batch_size, num_classes))\n",
    "x = batch_x\n",
    "x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "# Define lstm cells with tensorflow\n",
    "# Forward direction cell\n",
    "lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "# Backward direction cell\n",
    "lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "# Get lstm cell output\n",
    "try:\n",
    "    outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,dtype=tf.float32)\n",
    "except Exception: # Old TensorFlow version only returns outputs not states\n",
    "    outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,dtype=tf.float32)\n",
    "\n",
    "# Linear activation, using rnn inner loop last output then sigmoid result to get output in range [0,1]\n",
    "tf.nn.sigmoid(tf.matmul(outputs[-1], weights['out']) + biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
