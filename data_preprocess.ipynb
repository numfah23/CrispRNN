{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# input and setting: edit these\n",
    "#################################\n",
    "\n",
    "# file should have columns called \"sequence\" with 23 nts and \"effect\"\n",
    "filename = 'data/crispr_sample_input.csv'\n",
    "\n",
    "# percent of data to be split into train, val, test \n",
    "n_train, n_val, n_test = 80, 10, 10\n",
    "\n",
    "# type of model: either 'regression' or 'classification'\n",
    "model_type = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby sequence (for model, same seq can not have multiple effects)\n",
    "data = toppub_all_data.groupby(['sequence']).median()['effect'].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot function\n",
    "def one_hot(x):\n",
    "    e_dict = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1]}\n",
    "    return e_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6638872742071942, pvalue=0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot function\n",
    "\n",
    "e_dict = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1]}\n",
    "\n",
    "def one_hot(x):\n",
    "    return e_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encode the unique seqs, toppub\n",
    "one_hot_un_seq = unique_seq_toppub.apply(lambda x: map(one_hot, x))\n",
    "# doench\n",
    "one_hot_d = unique_seq_d.apply(lambda x: map(one_hot, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indices and append one_hot to df with seq, toppub\n",
    "unique_seq_toppub = unique_seq_toppub.reset_index()\n",
    "one_hot_un_seq = one_hot_un_seq.reset_index()\n",
    "groupby_gene = groupby_gene.reset_index()\n",
    "unique_seq_toppub['one_hot'] = one_hot_un_seq['sequence']\n",
    "# doench\n",
    "# reset indices and append one_hot to df with seq\n",
    "unique_seq_d = unique_seq_d.reset_index()\n",
    "one_hot_d = one_hot_d.reset_index()\n",
    "unique_seq_d['one_hot'] = one_hot_d['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge one hot encoding to data\n",
    "toppub_one_hot = toppub_grouped.merge(unique_seq_toppub,left_on=\"sequence\",right_on=\"sequence\", how=\"left\")\n",
    "d_one_hot = d_grouped.merge(unique_seq_d,left_on=\"sequence\",right_on=\"sequence\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge gene encoding to data # toppub only\n",
    "toppub_one_hot = toppub_one_hot.merge(groupby_gene,left_on=\"symbol\",right_on=\"symbol\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot features without gene, toppub\n",
    "features_no_gene = np.ndarray(shape=(toppub_one_hot.shape[0],23,4), dtype=int)\n",
    "for i in range(toppub_one_hot.shape[0]):\n",
    "    for j in range(len(toppub_one_hot['one_hot'][i])):\n",
    "        features_no_gene[i][j] = toppub_one_hot['one_hot'][i][j]\n",
    "        \n",
    "# one hot features without gene, toppub\n",
    "features_d = np.ndarray(shape=(d_one_hot.shape[0],23,4), dtype=int)\n",
    "for i in range(d_one_hot.shape[0]):\n",
    "    for j in range(len(d_one_hot['one_hot'][i])):\n",
    "        features_d[i][j] = d_one_hot['one_hot'][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "pickle.dump(features_no_gene, open(\"../features_no_gene.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot features with gene # toppub only\n",
    "# create empty numpy matrix for storing one hot features\n",
    "features = np.ndarray(shape=(toppub_one_hot.shape[0],23,5), dtype=int)\n",
    "# append gene to each one hot nucleotide\n",
    "for i in range(toppub_one_hot.shape[0]):\n",
    "    for j in range(len(toppub_one_hot['one_hot'][i])):\n",
    "        features[i][j] = toppub_one_hot['one_hot'][i][j] + [toppub_one_hot['index_y'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(features, open(\"../features.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regression\n",
    "def convert_labels(y):\n",
    "    return (y + 10)/float(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression labels\n",
    "labels = toppub_one_hot['effect']\n",
    "labels = np.array(list(map(lambda x: convert_labels(x), labels)))\n",
    "# doench\n",
    "labels_d = d_one_hot['effect']\n",
    "labels_d = np.array(list(map(lambda x: convert_labels(x), labels_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21-label classification labels\n",
    "num_classes=21\n",
    "labels_c = toppub_one_hot['effect']\n",
    "labels_c = np.array(list(map(lambda x: int(x+10), labels_c)))\n",
    "labels_c = np.eye(num_classes)[labels_c]\n",
    "# doench\n",
    "labels_d21 = d_one_hot['effect']\n",
    "labels_d21 = np.array(list(map(lambda x: int(x+10), labels_d21)))\n",
    "labels_d21 = np.eye(num_classes)[labels_d21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-label classification labels\n",
    "num_classes=3\n",
    "labels_3 = toppub_one_hot['effect']\n",
    "labels_3 = np.array(list(map(lambda x: int((x+10)/7), labels_3)))\n",
    "labels_3 = np.eye(num_classes)[labels_3]\n",
    "# doench\n",
    "labels_d3 = d_one_hot['effect']\n",
    "labels_d3 = np.array(list(map(lambda x: int((x+10)/7), labels_d3)))\n",
    "labels_d3 = np.eye(num_classes)[labels_d3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doench data, labels_d, labels_d21, labelsd_3\n",
    "pickle.dump(features_d, open(\"../d_data.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(labels_d, open(\"../d_labels_r.p\", \"wb\"))\n",
    "pickle.dump(labels_d21, open(\"../d_labels_21.p\", \"wb\"))\n",
    "pickle.dump(labels_d3, open(\"../d_labels_3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### for toppub only ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for with gene, regression\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features)) < 0.8\n",
    "\n",
    "train_data = features[msk]\n",
    "train_labels = labels[msk]\n",
    "\n",
    "test_val_data = features[~msk]\n",
    "test_val_labels = labels[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_GR.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_GR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_GR.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_GR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_GR.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_GR.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for no gene, regression\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features_no_gene)) < 0.8\n",
    "\n",
    "train_data = features_no_gene[msk]\n",
    "train_labels = labels[msk]\n",
    "\n",
    "test_val_data = features_no_gene[~msk]\n",
    "test_val_labels = labels[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with no gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_NR.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_NR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_NR.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_NR.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_NR.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_NR.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for with gene, 21 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features)) < 0.8\n",
    "\n",
    "train_data = features[msk]\n",
    "train_labels = labels_c[msk]\n",
    "\n",
    "test_val_data = features[~msk]\n",
    "test_val_labels = labels_c[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_G21.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_G21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_G21.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_G21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_G21.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_G21.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for with gene, 3 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features)) < 0.8\n",
    "\n",
    "train_data = features[msk]\n",
    "train_labels = labels_3[msk]\n",
    "\n",
    "test_val_data = features[~msk]\n",
    "test_val_labels = labels_3[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_G3.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_G3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_G3.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_G3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_G3.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_G3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for no gene, 21 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features_no_gene)) < 0.8\n",
    "\n",
    "train_data = features_no_gene[msk]\n",
    "train_labels = labels_c[msk]\n",
    "\n",
    "test_val_data = features_no_gene[~msk]\n",
    "test_val_labels = labels_c[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with no gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_N21.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_N21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_N21.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_N21.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_N21.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_N21.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing for no gene, 3 classes\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(features_no_gene)) < 0.8\n",
    "\n",
    "train_data = features_no_gene[msk]\n",
    "train_labels = labels_3[msk]\n",
    "\n",
    "test_val_data = features_no_gene[~msk]\n",
    "test_val_labels = labels_3[~msk]\n",
    "\n",
    "np.random.seed(23)\n",
    "msk = np.random.rand(len(test_val_data)) < 0.5\n",
    "test_data = test_val_data[msk]\n",
    "test_labels = test_val_labels[msk]\n",
    "\n",
    "val_data = test_val_data[~msk]\n",
    "val_labels = test_val_labels[~msk]\n",
    "\n",
    "# for with no gene, regression\n",
    "pickle.dump(train_data, open(\"../train_data_N3.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels_N3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data_N3.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels_N3.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data_N3.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels_N3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for with gene\n",
    "pickle.dump(train_data, open(\"../train_data.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification without gene\n",
    "pickle.dump(train_data, open(\"../train_data2.p\", \"wb\"))\n",
    "pickle.dump(train_labels, open(\"../train_labels2.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(test_data, open(\"../test_data2.p\", \"wb\"))\n",
    "pickle.dump(test_labels, open(\"../test_labels2.p\", \"wb\"))\n",
    "\n",
    "pickle.dump(val_data, open(\"../val_data2.p\", \"wb\"))\n",
    "pickle.dump(val_labels, open(\"../val_labels2.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
